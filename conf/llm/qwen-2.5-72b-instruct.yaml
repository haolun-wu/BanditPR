model: Qwen/Qwen2.5-72B-Instruct
provider: vllm
endpoint: ???
generate_config:
  max_completion_tokens: 256
  temperature: 0.7
  top_p: 0.8
