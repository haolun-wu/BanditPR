model: meta-llama/Meta-Llama-3-8B-Instruct
provider: local
generate_kwargs:
  batch_size: 1
  max_new_tokens: 256
  do_sample: true
  num_beams: 1
  temperature: 0.7
  top_p: 0.8
 